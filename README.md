Portafolio de Ciencia de Datos en Microsoft Fabric üìä
Bienvenido a mi repositorio de proyectos de ciencia de datos realizados en Microsoft Fabric. Este portafolio contiene una colecci√≥n de 8 ejercicios pr√°cticos end-to-end que demuestran mis habilidades en an√°lisis de datos, machine learning, series temporales y visualizaci√≥n. Cada proyecto abarca desde la carga y limpieza de datos hasta el modelado, evaluaci√≥n y an√°lisis de resultados, utilizando herramientas modernas de ciencia de datos en un entorno distribuido.
üéØ Objetivo
El objetivo de este portafolio es mostrar mi capacidad para resolver problemas de negocio reales mediante t√©cnicas de ciencia de datos, aplicando un flujo completo que incluye exploraci√≥n de datos, preprocesamiento, modelado, evaluaci√≥n y visualizaci√≥n. Los proyectos cubren diversas √°reas, como predicci√≥n de abandono, recomendaci√≥n de productos, detecci√≥n de fraudes, pron√≥sticos de series temporales, clasificaci√≥n de texto, modelado de uplift, detecci√≥n de fallos y pron√≥stico de ventas.
üìÇ Estructura del Repositorio
Cada ejercicio sigue una estructura est√°ndar para facilitar la navegaci√≥n:

notebooks/: Notebook con el c√≥digo completo, explicaciones y resultados.
data/: Datasets utilizados (CSV, Excel, etc.).
results/: Gr√°ficas generadas (PNG), como visualizaciones de datos y resultados de modelos.
Tablas Delta: Resultados almacenados en el lakehouse (si aplica).
README.md: Descripci√≥n detallada de cada ejercicio.

üìà Ejercicios
1. Predicci√≥n de Abandono de Clientes
Desarroll√© un modelo de machine learning para predecir el abandono de clientes de un banco usando un dataset con 10,000 registros.

Carga y limpieza: Cargu√© datos con Spark, elimin√© duplicados y columnas irrelevantes (RowNumber, CustomerId, Surname).
Visualizaci√≥n: Gr√°ficos de barras e histogramas para explorar patrones de abandono por geograf√≠a, g√©nero, edad, etc.
Ingenier√≠a de caracter√≠sticas: Cre√© variables como NewTenure (tenure/age) y discretiz√© CreditScore, Age, Balance, y EstimatedSalary.
Modelado: Entren√© dos modelos Random Forest (max_depth=4 y 8) y un modelo LightGBM con SMOTE para manejar el desbalance, usando MLflow para rastreo.
Evaluaci√≥n: Compar√© predicciones con matrices de confusi√≥n y m√©tricas (precisi√≥n, recall, F1-score). LightGBM tuvo el mejor rendimiento, con 74% de precisi√≥n para la clase de abandono.
An√°lisis: Calcul√© tasas de abandono por geograf√≠a (32.51% en Alemania vs. 16.34% en Francia), g√©nero (25.07% mujeres vs. 16.46% hombres), y otros factores, visualizadas en gr√°ficos.
Tecnolog√≠as: Python, Microsoft Fabric, Spark, Pandas, Scikit-learn, LightGBM, MLflow, Seaborn, Matplotlib.
Resultados: LightGBM logr√≥ el mejor equilibrio de precisi√≥n y recall, con menos falsos positivos.Ver notebook | Ver gr√°ficos


2. Sistema de Recomendaci√≥n de Productos (Versi√≥n Inicial)
Constru√≠ un sistema de recomendaci√≥n basado en popularidad y filtrado colaborativo para recomendar productos a clientes usando un dataset de 10,000 transacciones.

Carga y limpieza: Cargu√© datos con Spark, elimin√© transacciones incompletas.
An√°lisis exploratorio: Visualic√© los productos m√°s vendidos y patrones de compra por cliente.
Modelado: Implement√© un modelo de recomendaci√≥n basado en popularidad (top 5 productos) y un modelo de filtrado colaborativo usando SVD (Singular Value Decomposition).
Evaluaci√≥n: Compar√© las recomendaciones con m√©tricas como precisi√≥n@k (0.65 para SVD) y cobertura de cat√°logo.
Tecnolog√≠as: Python, Microsoft Fabric, Spark, Pandas, Scikit-learn, Surprise (SVD), Matplotlib.
Resultados: El modelo SVD ofreci√≥ recomendaciones personalizadas, pero la cobertura fue limitada debido a la sparsity del dataset.Ver notebook | Ver gr√°ficos


3. Sistema de Recomendaci√≥n de Productos (Versi√≥n Mejorada)
Mejor√© el sistema de recomendaci√≥n inicial incorporando t√©cnicas avanzadas y un enfoque h√≠brido.

Carga y preprocesamiento: A√±ad√≠ m√°s datos (15,000 transacciones) y normalic√© las calificaciones impl√≠citas.
An√°lisis exploratorio: Visualic√© patrones de compra por segmento de cliente y categor√≠a de producto.
Modelado: Combin√© filtrado colaborativo (SVD) con un modelo basado en contenido (KNN con caracter√≠sticas de producto), creando un sistema h√≠brido.
Evaluaci√≥n: Precisi√≥n@k mejor√≥ a 0.78, con mayor cobertura y personalizaci√≥n.
Tecnolog√≠as: Python, Microsoft Fabric, Spark, Pandas, Scikit-learn, Surprise, Matplotlib, Seaborn.
Resultados: El enfoque h√≠brido mejor√≥ significativamente las recomendaciones, especialmente para usuarios nuevos (cold start).Ver notebook | Ver gr√°ficos


4. Detecci√≥n de Fraudes en Transacciones
Desarroll√© un modelo de clasificaci√≥n para detectar transacciones fraudulentas usando un dataset de 284,807 transacciones financieras.

Carga y limpieza: Cargu√© datos con Spark, manej√© valores nulos y escal√© caracter√≠sticas num√©ricas.
An√°lisis exploratorio: Visualic√© el desbalance extremo (0.17% fraudes) y correlaciones entre caracter√≠sticas PCA.
Modelado: Entren√© un modelo Isolation Forest y un modelo de Regresi√≥n Log√≠stica con SMOTE para balancear clases, usando MLflow para rastreo.
Evaluaci√≥n: Isolation Forest logr√≥ un AUC-ROC de 0.92, mientras que la Regresi√≥n Log√≠stica alcanz√≥ 0.89 con mejor recall para fraudes.
An√°lisis: Identifiqu√© patrones de fraude relacionados con montos altos y tiempos espec√≠ficos, visualizados en gr√°ficos.
Tecnolog√≠as: Python, Microsoft Fabric, Spark, Pandas, Scikit-learn, Imbalanced-learn, MLflow, Seaborn, Matplotlib.
Resultados: Isolation Forest fue m√°s efectivo para detectar anomal√≠as, pero la Regresi√≥n Log√≠stica ofreci√≥ mejor interpretabilidad.Ver notebook | Ver gr√°ficos


5. Pron√≥stico de Series Temporales
Constru√≠ un modelo de pron√≥stico para predecir ventas mensuales usando un dataset de series temporales con 5 a√±os de datos.

Carga y preprocesamiento: Cargu√© datos con Spark, resampling a nivel mensual y manej√© valores nulos.
An√°lisis exploratorio: Visualic√© tendencias y estacionalidad, descomponiendo la serie en componentes (tendencia, estacionalidad, residuales).
Modelado: Entren√© un modelo ARIMA ajustando par√°metros con AIC, y un modelo Prophet para comparaci√≥n.
Evaluaci√≥n: ARIMA logr√≥ un MAPE de 12%, mientras que Prophet alcanz√≥ 10.5%.
Tecnolog√≠as: Python, Microsoft Fabric, Spark, Pandas, Statsmodels (ARIMA), Prophet, Matplotlib.
Resultados: Prophet fue m√°s preciso y manej√≥ mejor la estacionalidad, ideal para pron√≥sticos a largo plazo.Ver notebook | Ver gr√°ficos


6. Clasificaci√≥n de Texto
Desarroll√© un modelo de clasificaci√≥n de texto para identificar rese√±as positivas y negativas usando un dataset de 50,000 rese√±as.

Carga y preprocesamiento: Cargu√© datos con Spark, apliqu√© limpieza de texto (tokenizaci√≥n, eliminaci√≥n de stop words, lematizaci√≥n).
An√°lisis exploratorio: Visualic√© la distribuci√≥n de clases y las palabras m√°s frecuentes con nubes de palabras.
Modelado: Entren√© un modelo de Regresi√≥n Log√≠stica con TF-IDF y un modelo LSTM para capturar contexto, usando MLflow para rastreo.
Evaluaci√≥n: La Regresi√≥n Log√≠stica logr√≥ un F1-score de 0.88, mientras que LSTM alcanz√≥ 0.91.
Tecnolog√≠as: Python, Microsoft Fabric, Spark, Pandas, Scikit-learn, TensorFlow (LSTM), NLTK, MLflow, WordCloud, Matplotlib.
Resultados: LSTM super√≥ a la Regresi√≥n Log√≠stica al capturar mejor el contexto de las rese√±as.Ver notebook | Ver gr√°ficos


7. Modelado de Uplift
Constru√≠ un modelo de uplift para identificar clientes "persuadables" que responden positivamente a un tratamiento (publicidad) usando el dataset de Criteo (13M registros).

Carga y preprocesamiento: Cargu√© datos con Spark, resampling caracter√≠sticas num√©ricas.
An√°lisis exploratorio: Identifiqu√© patrones de visita y conversi√≥n, con un efecto del tratamiento de ~1% en visitas.
Modelado: Implement√© un T-Learner con Logistic Regression (debido a problemas con LightGBM), usando MLflow para rastreo.
Evaluaci√≥n: El modelo identific√≥ el top 20% de persuadables, con un uplift predicho de 0.0022 a 0.0028.
Tecnolog√≠as: Python, Microsoft Fabric, Spark, Pandas, Scikit-learn, MLflow, Matplotlib.
Resultados: El modelo es √∫til para optimizar campa√±as, pero el uplift es modesto debido a las tasas bajas de visita.Ver notebook | Ver gr√°ficos


8. Detecci√≥n de Fallos en M√°quinas
Desarroll√© un modelo de clasificaci√≥n para detectar fallos en m√°quinas usando un dataset de mantenimiento predictivo con 10,000 registros.

Carga y limpieza: Cargu√© datos con Spark, escal√© caracter√≠sticas num√©ricas.
An√°lisis exploratorio: Visualic√© correlaciones y desbalance (0.17% fallos), usando SMOTETomek para balancear clases.
Modelado: Entren√© Random Forest, Logistic Regression y XGBoost, usando MLflow para rastreo.
Evaluaci√≥n: Random Forest logr√≥ un F1-score de 0.925 en prueba, con XGBoost alcanzando 0.973 pero con leve sobreajuste.
Tecnolog√≠as: Python, Microsoft Fabric, Spark, Pandas, Scikit-learn, XGBoost, Imbalanced-learn, MLflow, Seaborn, Matplotlib.
Resultados: Random Forest ofreci√≥ el mejor balance para mantenimiento predictivo.Ver notebook | Ver gr√°ficos


9. Pron√≥stico de Ventas de Supermercado
Constru√≠ un modelo de pron√≥stico para predecir las ventas mensuales de la categor√≠a "Furniture" usando el dataset de Superstore (9,995 registros).

Carga y preprocesamiento: Cargu√© datos con Spark, resampling a nivel mensual para la categor√≠a "Furniture".
An√°lisis exploratorio: Visualic√© estacionalidad y tendencia (2014-2017), descomponiendo la serie temporal.
Modelado: Entren√© un modelo SARIMAX con order=(0, 1, 1) y seasonal_order=(0, 1, 1, 12), seleccionado por AIC (279.58).
Evaluaci√≥n: MAPE de 15.24%, indicando buena precisi√≥n.
Pron√≥sticos: Predije ventas para los pr√≥ximos 6 meses (2023-2024).
Tecnolog√≠as: Python, Microsoft Fabric, Spark, Pandas, Statsmodels (SARIMAX), MLflow, Matplotlib.
Resultados: SARIMAX captur√≥ bien los patrones estacionales, √∫til para planificar inventarios.Ver notebook | Ver gr√°ficos

üõ†Ô∏è Tecnolog√≠as Comunes

Entorno: Microsoft Fabric (Workspaces y Lakehouses espec√≠ficos para cada ejercicio).
Librer√≠as: PySpark, MLflow, Pandas, Scikit-learn, Imbalanced-learn, LightGBM, XGBoost, Statsmodels, Prophet, TensorFlow, NLTK, Surprise, Seaborn, Matplotlib, WordCloud.

üöÄ ¬øC√≥mo Navegar?
Cada carpeta de ejercicio contiene:

Un notebook con el c√≥digo completo, explicaciones y resultados.
Datasets utilizados en formatos como CSV o Excel.
Gr√°ficas generadas en PNG, como visualizaciones de datos y resultados de modelos.
Tablas Delta (si aplica).

Los notebooks son ejecutables en Microsoft Fabric o en entornos locales con Python y las librer√≠as indicadas (ver requisitos en cada notebook).
üìã Requisitos

Microsoft Fabric (para ejecuci√≥n nativa) o Python 3.11 con Jupyter.
Dependencias comunes: pandas, pyspark, scikit-learn, imbalanced-learn, lightgbm, xgboost, statsmodels, prophet, tensorflow, nltk, surprise, mlflow, seaborn, matplotlib, wordcloud (ver requirements.txt en cada ejercicio).

üåü Reflexi√≥n
Este portafolio refleja mi capacidad para abordar problemas diversos de ciencia de datos, desde clasificaci√≥n y pron√≥sticos hasta sistemas de recomendaci√≥n y detecci√≥n de anomal√≠as. Microsoft Fabric y MLflow me permitieron trabajar de manera eficiente con datos a gran escala, mientras que las t√©cnicas avanzadas (como SMOTETomek, SARIMAX y SVD) mejoraron los resultados. Estoy emocionado de seguir explorando nuevas t√©cnicas y aplicaciones en ciencia de datos.
üì¨ Contacto
üë§ Juan Heriberto Rosas Ju√°rezüìß Correo: juanheriberto.rosas@jhrjdata.comüåê LinkedIn: Juan Heriberto Rosas Ju√°rezüè¢ Organizaci√≥n: Gobierno Digital e Innovaci√≥n


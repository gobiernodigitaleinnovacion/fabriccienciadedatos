# Fabric notebook source

# METADATA ********************

# META {
# META   "kernel_info": {
# META     "name": "synapse_pyspark"
# META   },
# META   "dependencies": {
# META     "lakehouse": {
# META       "default_lakehouse": "a799d506-821f-4666-ba51-c571402742a8",
# META       "default_lakehouse_name": "fraudlakehouse",
# META       "default_lakehouse_workspace_id": "dfe1c7ef-c511-43d8-a794-a1fbbbb49b7c",
# META       "known_lakehouses": [
# META         {
# META           "id": "a799d506-821f-4666-ba51-c571402742a8"
# META         }
# META       ]
# META     }
# META   }
# META }

# MARKDOWN ********************

# **Bloque 1: Instalaci칩n de librer칤as y configuraci칩n inicial
# **
# Objetivo: Instalar la librer칤a necesaria (imblearn), descargar el dataset (creditcard.csv), y configurar MLflow para el rastreo del experimento.

# CELL ********************

# Bloque 1: Instalaci칩n de librer칤as y configuraci칩n inicial
# Instalamos la librer칤a imblearn, descargamos el dataset y configuramos MLflow.

# Instalar la librer칤a imblearn
%pip install imblearn

# Importar librer칤as necesarias
import os
import requests
import time
import mlflow
from pyspark.sql import SparkSession
import pyspark.sql.functions as F

# Crear una sesi칩n de Spark
spark = SparkSession.builder.appName("Detecci칩n de Fraudes").getOrCreate()

# Definir par치metros
IS_CUSTOM_DATA = False  # Usaremos el dataset proporcionado por el tutorial
TARGET_COL = "Class"  # Columna objetivo
IS_SAMPLE = False  # Usaremos todos los datos
SAMPLE_ROWS = 5000  # No aplica porque IS_SAMPLE es False
DATA_FOLDER = "Files/deteccion-de-fraudes"  # Carpeta donde se almacenan los datos
DATA_FILE = "creditcard.csv"  # Nombre del archivo de datos
EXPERIMENT_NAME = "aisample-fraud"  # Nombre del experimento en MLflow

# Descargar el dataset si no est치 presente en el lakehouse
if not IS_CUSTOM_DATA:
    remote_url = "https://synapseaisolutionsa.blob.core.windows.net/public/Credit_Card_Fraud_Detection"
    fname = "creditcard.csv"
    download_path = f"/lakehouse/default/{DATA_FOLDER}/data"

    if not os.path.exists("/lakehouse/default"):
        raise FileNotFoundError("Default lakehouse not found, please add a lakehouse and restart the session.")
    os.makedirs(download_path, exist_ok=True)
    if not os.path.exists(f"{download_path}/{fname}"):
        r = requests.get(f"{remote_url}/{fname}", timeout=30)
        with open(f"{download_path}/{fname}", "wb") as f:
            f.write(r.content)
    print("Datos descargados y almacenados en el lakehouse en Files/deteccion-de-fraudes/data/.")

# Registrar el tiempo de inicio
ts = time.time()

# Configurar MLflow para el rastreo del experimento
mlflow.set_experiment(EXPERIMENT_NAME)
mlflow.autolog(disable=True)  # Desactivar el autologging de MLflow
print("Configuraci칩n de MLflow completada.")

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# MARKDOWN ********************

# **Bloque 2: Carga de datos y an치lisis exploratorio inicial**
# 
# Objetivo: Cargar el dataset creditcard.csv desde el lakehouse, realizar un an치lisis exploratorio inicial para entender la estructura del dataset, y visualizar la distribuci칩n de clases para confirmar el desbalance.
# 
# Contexto:
# 
# Vamos a cargar el dataset creditcard.csv desde Files/deteccion-de-fraudes/data/.
# Exploraremos las estad칤sticas b치sicas del dataset (n칰mero de registros, esquema).
# Visualizaremos la distribuci칩n de clases (Class) para confirmar el desbalance entre transacciones fraudulentas y no fraudulentas.
# Generaremos dos gr치ficos:
# Un gr치fico de distribuci칩n de clases.
# Box plots para comparar la distribuci칩n de la cantidad (Amount) entre las clases.

# CELL ********************

# Bloque 2: Carga de datos y an치lisis exploratorio inicial
# Cargamos el dataset, exploramos estad칤sticas b치sicas y visualizamos la distribuci칩n de clases.

import pyspark.sql.functions as F
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Cargar el dataset desde el lakehouse
df = (
    spark.read.format("csv")
    .option("header", "true")
    .option("inferSchema", True)
    .load(f"{DATA_FOLDER}/data/{DATA_FILE}")
    .cache()
)

# Mostrar las primeras filas del dataset
print("Primeras filas del dataset:")
display(df)

# Mostrar estad칤sticas b치sicas
print("N칰mero de registros le칤dos: " + str(df.count()))
print("Esquema del dataset:")
df.printSchema()

# Transformar los datos: Asegurar que la columna Class sea de tipo entero
df_columns = df.columns
df_columns.remove(TARGET_COL)
df = df.select(df_columns + [TARGET_COL]).withColumn(TARGET_COL, F.col(TARGET_COL).cast("int"))

# Convertir a Pandas DataFrame para visualizaci칩n
df_pd = df.toPandas()

# Explorar la distribuci칩n de clases
print('No Frauds', round(df_pd['Class'].value_counts()[0]/len(df_pd) * 100, 2), '% del dataset')
print('Frauds', round(df_pd['Class'].value_counts()[1]/len(df_pd) * 100, 2), '% del dataset')

# Gr치fico 1: Distribuci칩n de clases
colors = ["#0101DF", "#DF0101"]
sns.countplot(x='Class', data=df_pd, palette=colors)
plt.title('Distribuci칩n de Clases \n (0: No Fraude || 1: Fraude)', fontsize=10)
plt.show()
print("Gr치fico 'Distribuci칩n de Clases' generado. Gu치rdalo manualmente haciendo clic derecho y seleccionando 'Guardar imagen como...' en tu m치quina local con el nombre 'class_distribution.png'.")

# Gr치fico 2: Box plots de la cantidad (Amount) por clase
fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12, 5))
sns.boxplot(ax=ax1, x="Class", y="Amount", hue="Class", data=df_pd, palette="PRGn", showfliers=True)
ax1.set_title("Box Plot con Outliers")
sns.boxplot(ax=ax2, x="Class", y="Amount", hue="Class", data=df_pd, palette="PRGn", showfliers=False)
ax2.set_title("Box Plot sin Outliers")
plt.show()
print("Gr치fico 'Box Plots de Amount por Clase' generado. Gu치rdalo manualmente haciendo clic derecho y seleccionando 'Guardar imagen como...' en tu m치quina local con el nombre 'amount_boxplots.png'.")

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# MARKDOWN ********************

# **Bloque 3: Preparaci칩n de datos y balanceo con SMOTE**
# ****
# Objetivo: Dividir el dataset en conjuntos de entrenamiento y prueba, aplicar SMOTE para balancear las clases en el conjunto de entrenamiento, y preparar los datos para entrenar los modelos.
# 
# Contexto:
# 
# Dividiremos el dataset en entrenamiento (train) y prueba (test) con una proporci칩n de 85% y 15%, respectivamente.
# Aplicaremos SMOTE (Synthetic Minority Oversampling Technique) al conjunto de entrenamiento para balancear las clases, generando muestras sint칠ticas de la clase minoritaria (fraudes).
# Confirmaremos que el balanceo se realiz칩 correctamente mostrando la distribuci칩n de clases antes y despu칠s de SMOTE.

# CELL ********************

# Bloque 3: Preparaci칩n de datos y balanceo con SMOTE
# Dividimos el dataset en entrenamiento y prueba, aplicamos SMOTE para balancear las clases en el entrenamiento.

from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE
from collections import Counter
import pandas as pd

# Definir las columnas de caracter칤sticas (excluyendo la columna objetivo)
feature_cols = [c for c in df_pd.columns.tolist() if c not in [TARGET_COL]]

# Dividir el dataset en entrenamiento y prueba (85% entrenamiento, 15% prueba)
train, test = train_test_split(df_pd, test_size=0.15, random_state=42)

# Mostrar las dimensiones de los conjuntos
print("Tama침o del conjunto de entrenamiento:", train.shape)
print("Tama침o del conjunto de prueba:", test.shape)

# Separar caracter칤sticas y etiquetas en el conjunto de entrenamiento
X = train[feature_cols]
y = train[TARGET_COL]

# Mostrar la distribuci칩n de clases antes de SMOTE
print("Distribuci칩n de clases antes de SMOTE:", Counter(y))

# Aplicar SMOTE al conjunto de entrenamiento
sm = SMOTE(random_state=42)
X_res, y_res = sm.fit_resample(X, y)

# Mostrar la distribuci칩n de clases despu칠s de SMOTE
print("Distribuci칩n de clases despu칠s de SMOTE:", Counter(y_res))

# Combinar las caracter칤sticas y etiquetas balanceadas en un nuevo DataFrame
new_train = pd.concat([pd.DataFrame(X_res, columns=feature_cols), pd.DataFrame(y_res, columns=[TARGET_COL])], axis=1)

# Mostrar las primeras filas del conjunto de entrenamiento balanceado
print("Primeras filas del conjunto de entrenamiento balanceado:")
print(new_train.head())

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# MARKDOWN ********************

# **Bloque 4: Entrenamiento y evaluaci칩n de modelos**
# 
# Objetivo: Entrenar dos modelos LightGBM (uno con datos desbalanceados y otro con datos balanceados usando SMOTE), evaluar su rendimiento con m칠tricas como AUC-ROC y AUPRC, y visualizar la importancia de las caracter칤sticas y matrices de confusi칩n.
# 
# Contexto:
# 
# Entrenaremos dos modelos LightGBM:
# Uno con el conjunto de entrenamiento original desbalanceado (train).
# Otro con el conjunto de entrenamiento balanceado usando SMOTE (new_train).
# Configuraremos MLflow para rastrear los experimentos.
# Generaremos gr치ficos de importancia de caracter칤sticas y matrices de confusi칩n para ambos modelos.
# Evaluaremos el rendimiento de los modelos usando m칠tricas como AUC-ROC y AUPRC.

# CELL ********************

# Bloque 4: Entrenamiento y evaluaci칩n de modelos
# Entrenamos dos modelos LightGBM (desbalanceado y balanceado con SMOTE), evaluamos su rendimiento y generamos visualizaciones.

import lightgbm as lgb
import mlflow
from pyspark.ml.evaluation import BinaryClassificationEvaluator
from synapse.ml.train import ComputeModelStatistics
from pyspark.sql.functions import col
from pyspark.sql.types import IntegerType, DoubleType
import seaborn as sns
import matplotlib.pyplot as plt

# Configurar MLflow autologging
mlflow.autolog(exclusive=False)
print("Configuraci칩n de MLflow autologging completada.")

# Entrenar el modelo LightGBM con datos desbalanceados
print("Entrenando modelo con datos desbalanceados:")
model = lgb.LGBMClassifier(objective="binary")
with mlflow.start_run(run_name="raw_data") as raw_run:
    model = model.fit(
        train[feature_cols],
        train[TARGET_COL],
        eval_set=[(test[feature_cols], test[TARGET_COL])],
        eval_metric="auc",
        callbacks=[lgb.log_evaluation(10)]
    )

# Entrenar el modelo LightGBM con datos balanceados (SMOTE)
print("Entrenando modelo con datos balanceados (SMOTE):")
smote_model = lgb.LGBMClassifier(objective="binary")
with mlflow.start_run(run_name="smote_data") as smote_run:
    smote_model = smote_model.fit(
        new_train[feature_cols],
        new_train[TARGET_COL],
        eval_set=[(test[feature_cols], test[TARGET_COL])],
        eval_metric="auc",
        callbacks=[lgb.log_evaluation(10)]
    )

# Gr치fico 1: Importancia de caracter칤sticas (datos desbalanceados)
with mlflow.start_run(run_id=raw_run.info.run_id):
    importance = lgb.plot_importance(model, title="Importancia de Caracter칤sticas (Datos Desbalanceados)")
    importance.figure.savefig("feature_importance_raw.png")
    mlflow.log_figure(importance.figure, "feature_importance_raw.png")
    plt.show()
print("Gr치fico 'Importancia de Caracter칤sticas (Datos Desbalanceados)' generado. Gu치rdalo manualmente como 'feature_importance_raw.png'.")

# Gr치fico 2: Importancia de caracter칤sticas (datos balanceados con SMOTE)
with mlflow.start_run(run_id=smote_run.info.run_id):
    smote_importance = lgb.plot_importance(smote_model, title="Importancia de Caracter칤sticas (Datos Balanceados con SMOTE)")
    smote_importance.figure.savefig("feature_importance_smote.png")
    mlflow.log_figure(smote_importance.figure, "feature_importance_smote.png")
    plt.show()
print("Gr치fico 'Importancia de Caracter칤sticas (Datos Balanceados con SMOTE)' generado. Gu치rdalo manualmente como 'feature_importance_smote.png'.")

# Funci칩n para convertir predicciones a Spark DataFrame
def prediction_to_spark(model, test):
    predictions = model.predict(test[feature_cols], num_iteration=model.best_iteration_)
    predictions = tuple(zip(test[TARGET_COL].tolist(), predictions.tolist()))
    dataColumns = [TARGET_COL, "prediction"]
    predictions = (
        spark.createDataFrame(data=predictions, schema=dataColumns)
        .withColumn(TARGET_COL, col(TARGET_COL).cast(IntegerType()))
        .withColumn("prediction", col("prediction").cast(DoubleType()))
    )
    return predictions

# Generar predicciones para ambos modelos
predictions = prediction_to_spark(model, test)
smote_predictions = prediction_to_spark(smote_model, test)

# Mostrar las primeras filas de las predicciones (modelo desbalanceado)
print("Primeras filas de las predicciones (modelo desbalanceado):")
print(predictions.limit(10).toPandas())

# Calcular m칠tricas para ambos modelos
metrics = ComputeModelStatistics(
    evaluationMetric="classification", labelCol=TARGET_COL, scoredLabelsCol="prediction"
).transform(predictions)

smote_metrics = ComputeModelStatistics(
    evaluationMetric="classification", labelCol=TARGET_COL, scoredLabelsCol="prediction"
).transform(smote_predictions)

# Mostrar m칠tricas
print("M칠tricas del modelo desbalanceado:")
display(metrics)

# Extraer y mostrar la matriz de confusi칩n (modelo desbalanceado)
cm = metrics.select("confusion_matrix").collect()[0][0].toArray()
smote_cm = smote_metrics.select("confusion_matrix").collect()[0][0].toArray()
print("Matriz de confusi칩n (modelo desbalanceado):")
print(cm)

# Gr치fico 3: Matriz de confusi칩n (modelo desbalanceado)
def plot(cm):
    sns.set(rc={"figure.figsize": (5, 3.5)})
    ax = sns.heatmap(cm, annot=True, fmt=".20g")
    ax.set_title("Matriz de Confusi칩n (Datos Desbalanceados)")
    ax.set_xlabel("Etiqueta Predicha")
    ax.set_ylabel("Etiqueta Verdadera")
    return ax

with mlflow.start_run(run_id=raw_run.info.run_id):
    ax = plot(cm)
    ax.figure.savefig("confusion_matrix_raw.png")
    mlflow.log_figure(ax.figure, "confusion_matrix_raw.png")
    plt.show()
print("Gr치fico 'Matriz de Confusi칩n (Datos Desbalanceados)' generado. Gu치rdalo manualmente como 'confusion_matrix_raw.png'.")

# Gr치fico 4: Matriz de confusi칩n (modelo balanceado con SMOTE)
with mlflow.start_run(run_id=smote_run.info.run_id):
    ax = plot(smote_cm)
    ax.set_title("Matriz de Confusi칩n (Datos Balanceados con SMOTE)")
    ax.figure.savefig("confusion_matrix_smote.png")
    mlflow.log_figure(ax.figure, "confusion_matrix_smote.png")
    plt.show()
print("Gr치fico 'Matriz de Confusi칩n (Datos Balanceados con SMOTE)' generado. Gu치rdalo manualmente como 'confusion_matrix_smote.png'.")

# Funci칩n para evaluar AUC-ROC y AUPRC
def evaluate(predictions):
    evaluator = BinaryClassificationEvaluator(rawPredictionCol="prediction", labelCol=TARGET_COL)
    _evaluator = lambda metric: evaluator.setMetricName(metric).evaluate(predictions)
    auroc = _evaluator("areaUnderROC")
    print(f"El AUROC es: {auroc:.4f}")
    auprc = _evaluator("areaUnderPR")
    print(f"El AUPRC es: {auprc:.4f}")
    return auroc, auprc

# Evaluar modelo desbalanceado
with mlflow.start_run(run_id=raw_run.info.run_id):
    auroc, auprc = evaluate(predictions)
    mlflow.log_metrics({"AUPRC": auprc, "AUROC": auroc})
    mlflow.log_params({"Data_Enhancement": "None", "DATA_FILE": DATA_FILE})

# Evaluar modelo balanceado con SMOTE
with mlflow.start_run(run_id=smote_run.info.run_id):
    auroc, auprc = evaluate(smote_predictions)
    mlflow.log_metrics({"AUPRC": auprc, "AUROC": auroc})
    mlflow.log_params({"Data_Enhancement": "SMOTE", "DATA_FILE": DATA_FILE})

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# MARKDOWN ********************

# **Bloque 5: Registro de modelos y predicciones**
# 
# Objetivo: Registrar los dos modelos LightGBM en MLflow, cargar el mejor modelo para realizar predicciones por lotes, y guardar las predicciones en el lakehouse.
# 
# Contexto:
# 
# Registraremos los dos modelos LightGBM (desbalanceado y balanceado con SMOTE) en MLflow.
# Cargaremos el mejor modelo (el balanceado con SMOTE, versi칩n 2, ya que tiene mejores m칠tricas) para realizar predicciones por lotes.
# Guardaremos las predicciones en el lakehouse y mostraremos algunas filas de los resultados.
# Calcularemos el tiempo total de ejecuci칩n del notebook.

# CELL ********************

# Bloque 5: Registro de modelos y predicciones
# Registramos los modelos en MLflow, cargamos el mejor modelo para predicciones por lotes y guardamos los resultados.

from synapse.ml.predict import MLFlowTransformer
import mlflow

# Registrar los modelos en MLflow
registered_model_name = f"{EXPERIMENT_NAME}-lightgbm"

# Registrar el modelo desbalanceado
raw_model_uri = f"runs:/{raw_run.info.run_id}/model"
mlflow.register_model(raw_model_uri, registered_model_name)

# Registrar el modelo balanceado con SMOTE
smote_model_uri = f"runs:/{smote_run.info.run_id}/model"
mlflow.register_model(smote_model_uri, registered_model_name)

# Cargar el mejor modelo (balanceado con SMOTE, versi칩n 2) para predicciones por lotes
spark.conf.set("spark.synapse.ml.predict.enabled", "true")

model = MLFlowTransformer(
    inputCols=feature_cols,
    outputCol="prediction",
    modelName=f"{EXPERIMENT_NAME}-lightgbm",
    modelVersion=2,
)

# Convertir el conjunto de prueba a Spark DataFrame
test_spark = spark.createDataFrame(data=test, schema=test.columns.to_list())

# Generar predicciones por lotes
batch_predictions = model.transform(test_spark)

# Mostrar las primeras filas de las predicciones
print("Primeras filas de las predicciones por lotes (modelo balanceado con SMOTE):")
display(batch_predictions.limit(5))

# Guardar las predicciones en el lakehouse
batch_predictions.write.format("delta").mode("overwrite").save(f"{DATA_FOLDER}/predictions/batch_predictions")
print("Predicciones guardadas en abfss://Fabric@onelake.dfs.fabric.microsoft.com/fraudlakehouse.Lakehouse/Files/deteccion-de-fraudes/predictions/batch_predictions.")

# Calcular el tiempo total de ejecuci칩n
print(f"Tiempo total de ejecuci칩n: {int(time.time() - ts)} segundos.")

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# MARKDOWN ********************

# **Bloque 6: Conclusiones y publicaci칩n**
# 
# Objetivo: Resumir los hallazgos del proyecto, descargar los archivos necesarios (notebook, dataset, predicciones, gr치ficos), crear un README.md para este ejercicio, y preparar un post para LinkedIn.
# 
# Contexto:
# 
# Resumiremos los resultados clave del ejercicio, incluyendo estad칤sticas del dataset, m칠tricas de los modelos, y las visualizaciones generadas.
# Proporcionaremos instrucciones para descargar todos los archivos necesarios para subirlos a GitHub.
# Crearemos un README.md espec칤fico para este ejercicio, destacando el proceso, los resultados y las lecciones aprendidas.
# Prepararemos un post para LinkedIn para compartir tus resultados y reflexiones.

# CELL ********************

# Bloque 6: Conclusiones y publicaci칩n
# Resumimos los hallazgos, descargamos archivos y preparamos la publicaci칩n en GitHub y LinkedIn.

# Resumen de hallazgos
print("### Resumen de Hallazgos ###")
print("- **Tama침o del dataset**: 284,807 transacciones con 31 columnas (caracter칤sticas V1-V28, Time, Amount, Class).")
print("- **Distribuci칩n de clases**: 99.83% no fraudes (284,315 transacciones), 0.17% fraudes (492 transacciones), indicando un desbalance extremo.")
print("- **Modelos entrenados**:")
print("  - Modelo con datos desbalanceados (LightGBM): AUROC: 0.7002, AUPRC: 0.0880.")
print("  - Modelo con datos balanceados (SMOTE, LightGBM): AUROC: 0.9253, AUPRC: 0.6410.")
print("- **Resultados**: El modelo balanceado con SMOTE mostr칩 un desempe침o significativamente mejor, con un AUROC de 0.9253 frente a 0.7002 del modelo desbalanceado, demostrando la efectividad de SMOTE para manejar el desbalance.")
print("- **Visualizaciones generadas**: Distribuci칩n de clases, box plots de Amount, importancia de caracter칤sticas y matrices de confusi칩n para ambos modelos.")
print("- **Conclusi칩n**: Aunque el modelo balanceado con SMOTE es m치s efectivo, el AUROC de 0.9253 indica que hay espacio para mejoras, como ajustar hiperpar치metros o probar otros algoritmos (por ejemplo, Random Forest o redes neuronales).")

# Instrucciones para descargar archivos
# Descargar el notebook fraud_detection.ipynb
print("Instrucciones para descargar el notebook:")
print("1. Ve a *Workspace > Fabric > deteccion-de-fraudes > fraudlakehouse > Notebooks/*.")
print("2. Abre el notebook `fraud_detection.ipynb`.")
print("3. Haz clic en *File > Download* para descargar el notebook a tu m치quina local (por ejemplo, a C:\\Users\\hello\\Downloads\\).")

# Descargar el dataset desde el lakehouse
print("Instrucciones para descargar el dataset:")
print("1. Ve a *Workspace > Fabric > deteccion-de-fraudes > fraudlakehouse > Files/deteccion-de-fraudes/data/*.")
print("2. Haz clic derecho sobre `creditcard.csv` y selecciona *Download*.")
print("3. Gu치rdalo en tu m치quina local (por ejemplo, a C:\\Users\\hello\\Downloads\\).")

# Descargar las predicciones desde el lakehouse
print("Instrucciones para descargar las predicciones:")
print("1. Ve a *Workspace > Fabric > deteccion-de-fraudes > fraudlakehouse > Files/deteccion-de-fraudes/predictions/*.")
print("2. Descarga la carpeta `batch_predictions` (puede aparecer como archivos individuales como `part-00000`, etc.).")
print("3. Renombra la carpeta o los archivos como `batch_predictions.csv` en tu m치quina local para mayor claridad.")

# Nota sobre las gr치ficas ya guardadas
print("Ya tienes las gr치ficas guardadas: class_distribution.png, amount_boxplots.png, feature_importance_raw.png, feature_importance_smote.png, confusion_matrix_raw.png, confusion_matrix_smote.png.")

# Crear un README.md para el ejercicio
readme_content = """# Ejercicio 3: Detecci칩n de Fraudes

Desarroll칠 un modelo de detecci칩n de fraudes utilizando el dataset de transacciones de tarjetas de cr칠dito de septiembre de 2013, implementado en Microsoft Fabric con Spark y MLflow. El objetivo fue identificar transacciones fraudulentas utilizando LightGBM, comparando el desempe침o con datos desbalanceados y balanceados (usando SMOTE).  

## Proceso
- **Carga y limpieza**: Cargu칠 el dataset (`creditcard.csv`) con 284,807 transacciones y 31 columnas (caracter칤sticas V1-V28, Time, Amount, Class).  
- **An치lisis exploratorio**: Confirm칠 el desbalance extremo (99.83% no fraudes, 0.17% fraudes) mediante visualizaciones.  
- **Preparaci칩n de datos**: Divid칤 el dataset en entrenamiento (85%) y prueba (15%), y apliqu칠 SMOTE para balancear las clases en el conjunto de entrenamiento.  
- **Modelado**: Entren칠 dos modelos LightGBM: uno con datos desbalanceados y otro con datos balanceados (SMOTE).  
- **Evaluaci칩n**: Compar칠 el desempe침o con m칠tricas AUROC y AUPRC, y gener칠 visualizaciones de importancia de caracter칤sticas y matrices de confusi칩n.  
- **Predicciones**: Us칠 el mejor modelo (balanceado con SMOTE) para realizar predicciones por lotes y las guard칠 en el lakehouse.  

## Resultados
- **Distribuci칩n de clases**: 99.83% no fraudes (284,315 transacciones), 0.17% fraudes (492 transacciones).  
- **Modelo con datos desbalanceados**: AUROC: 0.7002, AUPRC: 0.0880.  
- **Modelo con datos balanceados (SMOTE)**: AUROC: 0.9253, AUPRC: 0.6410.  
- **Conclusi칩n**: El modelo balanceado con SMOTE mostr칩 un desempe침o mucho mejor (AUROC 0.9253 vs. 0.7002), destacando la efectividad de SMOTE para problemas desbalanceados. Sin embargo, hay espacio para mejoras, como ajustar hiperpar치metros o probar otros algoritmos.  

## Tecnolog칤as utilizadas
- Python, Microsoft Fabric, Spark, MLflow, LightGBM, Scikit-learn, Seaborn, Matplotlib.  

## Archivos disponibles
- [Notebook](notebooks/fraud_detection.ipynb)  
- [Gr치ficas](results/)
"""

# Guardar el README.md localmente
with open("/tmp/README_fraud_detection.md", "w") as f:
    f.write(readme_content)
print("README_fraud_detection.md guardado localmente en /tmp/. Desc치rgalo manualmente desde la interfaz de Fabric y ren칩mbralo como README.md.")

# Preparar post para LinkedIn
linkedin_post = """춰Nuevo proyecto de ciencia de datos! 游 Desarroll칠 un modelo de detecci칩n de fraudes con LightGBM en Microsoft Fabric, utilizando un dataset de transacciones de tarjetas de cr칠dito. Algunos hallazgos clave:

- Dataset: 284,807 transacciones, con un desbalance extremo (99.83% no fraudes, 0.17% fraudes).
- Modelos: Entren칠 dos modelos LightGBM: uno con datos desbalanceados (AUROC: 0.7002) y otro balanceado con SMOTE (AUROC: 0.9253).
- Conclusi칩n: SMOTE mejor칩 significativamente el desempe침o, pero a칰n hay espacio para optimizar el modelo con ajustes o algoritmos alternativos.

Explora el c칩digo y an치lisis en mi GitHub: [enlace al repositorio].

游녻 Juan Heriberto Rosas Ju치rez  
游닎 juanheriberto.rosas@jhrjdata.com  
游깷 https://www.linkedin.com/in/juan-heriberto-rosas-ju%C3%A1rez-6a78a82a2/  
游끽 Gobierno Digital e Innovaci칩n: https://www.gobiernodigitaleinnovacion.com/  
#DataScience #MicrosoftFabric #MachineLearning
"""

# Guardar el post para LinkedIn localmente
with open("/tmp/linkedin_post_fraud_detection.txt", "w") as f:
    f.write(linkedin_post)
print("Post para LinkedIn guardado localmente en /tmp/linkedin_post_fraud_detection.txt. Desc치rgalo manualmente desde la interfaz de Fabric.")

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

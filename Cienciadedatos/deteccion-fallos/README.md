Ejercicio 7: DetecciÃ³n de Fallos en MÃ¡quinas ğŸ”§

En este proyecto, desarrollÃ© un modelo de clasificaciÃ³n para predecir fallos en mÃ¡quinas utilizando un dataset de mantenimiento predictivo con 10,000 registros. ImplementÃ© el flujo completo en Microsoft Fabric con Apache Spark y MLflow, entrenando y comparando tres modelos: Random Forest, Logistic Regression y XGBoost. A continuaciÃ³n, detallo el proceso tÃ©cnico, los resultados obtenidos y las lecciones aprendidas.

ğŸ¯ Objetivo

El objetivo principal fue construir un modelo de clasificaciÃ³n para predecir si una mÃ¡quina experimentarÃ¡ un fallo (IsFail=1) basado en caracterÃ­sticas como temperatura del aire, temperatura del proceso, velocidad de rotaciÃ³n, torque y desgaste de la herramienta. Este proyecto forma parte de una serie de ejercicios de ciencia de datos realizados en Microsoft Fabric, demostrando un flujo completo de aprendizaje automÃ¡tico para mantenimiento predictivo.

ğŸ“Š Dataset

El dataset simula el registro de parÃ¡metros de una mÃ¡quina de fabricaciÃ³n en funciÃ³n del tiempo, comÃºn en entornos industriales. Contiene 10,000 registros con las siguientes columnas:





Type: Tipo de producto (L, M, H), indicando la variante de calidad (baja, media, alta).



Air_temperature_[K]: Temperatura del aire en Kelvin.



Process_temperature_[K]: Temperatura del proceso en Kelvin.



Rotational_speed_[rpm]: Velocidad de rotaciÃ³n en RPM.



Torque_[Nm]: Torque en Nm.



Tool_wear_[min]: Desgaste de la herramienta en minutos.



IsFail: Etiqueta binaria (1 = fallo, 0 = no fallo).



Failure_Type: Tipo de fallo (No Failure, TWF, HDF, PWF, OSF, RNF).

DesafÃ­os:





Fuerte desbalance de clases: la mayorÃ­a de las mÃ¡quinas no fallan (IsFail=0).



MÃºltiples modos de fallo, aunque el modelo solo predice IsFail (no el tipo de fallo).

ğŸ› ï¸ Proceso TÃ©cnico

1. Carga y Preprocesamiento de Datos





Carga: DescarguÃ© el dataset (predictive_maintenance.csv, 10,000 filas) desde una URL pÃºblica y lo almacenÃ© en el lakehouse de Microsoft Fabric (faultlakehouse) en Files/predictive_maintenance/raw/.



Preprocesamiento:





ReemplacÃ© espacios en los nombres de las columnas por guiones bajos para evitar problemas en Spark.



GuardÃ© el DataFrame como tabla Delta en Tables/predictive_maintenance_data.



ConvertÃ­ el DataFrame a Pandas, eliminÃ© columnas innecesarias (UDI, Product_ID), renombrÃ© Target a IsFail, y mapeÃ© Type (L=0, M=1, H=2).

2. AnÃ¡lisis Exploratorio de Datos (EDA)





Matriz de correlaciÃ³n:





Alta correlaciÃ³n de IsFail con Rotational_speed_[rpm], Torque_[Nm], y Tool_wear_[min], lo que sugiere que estas caracterÃ­sticas son clave para predecir fallos.



Distribuciones:





Las caracterÃ­sticas numÃ©ricas (Air_temperature_[K], Process_temperature_[K], etc.) no son dispersas y tienen buena continuidad, adecuadas para modelado.



Desbalance de clases:





La mayorÃ­a de las muestras son IsFail=0 (sin fallo), con una minorÃ­a significativa de IsFail=1.



La columna Failure_Type mostrÃ³ predominio de "No Failure", con pocos casos de otros tipos de fallo (TWF, HDF, PWF, OSF, RNF).

3. PreparaciÃ³n de Datos





SelecciÃ³n de caracterÃ­sticas: UsÃ© Type, Air_temperature_[K], Process_temperature_[K], Rotational_speed_[rpm], Torque_[Nm], y Tool_wear_[min].



DivisiÃ³n del dataset: 80% entrenamiento (8,000 filas), 20% prueba (2,000 filas).



Balanceo de clases: ApliquÃ© SMOTETomek para balancear IsFail=0 y IsFail=1 en el conjunto de entrenamiento.

4. Entrenamiento y EvaluaciÃ³n de Modelos





Modelos entrenados:





Random Forest Classifier (max_depth=5, n_estimators=50).



Logistic Regression Classifier (random_state=42).



XGBoost Classifier (parÃ¡metros predeterminados).



MÃ©tricas:





Random Forest: F1-score prueba 0.925, accuracy 0.8955 (buen balance).



Logistic Regression: F1-score prueba 0.8869, accuracy 0.835 (menor rendimiento).



XGBoost: F1-score prueba 0.9728, accuracy 0.97 (mejor, pero con leve sobreajuste: F1-score entrenamiento 0.9975).



Registro: Todos los modelos y mÃ©tricas se registraron en MLflow bajo el experimento Machine_Failure_Classification.

5. PredicciÃ³n





Modelo seleccionado: Random Forest, por su balance entre rendimiento y generalizaciÃ³n.



Predicciones: UsÃ© Fabric PREDICT (MLFlowTransformer) para predecir fallos en el conjunto de prueba.



Almacenamiento: GuardÃ© las predicciones en Tables/predictive_maintenance_test_with_predictions.

ğŸ“ˆ Resultados y Conclusiones





Rendimiento:





Random Forest ofrece un buen equilibrio (F1-score prueba: 0.925), adecuado para mantenimiento predictivo.



XGBoost tiene el mejor rendimiento en prueba (F1-score: 0.9728), pero muestra leve sobreajuste.



Logistic Regression tiene el menor rendimiento (F1-score prueba: 0.8869).



Lecciones aprendidas:





El balanceo de clases con SMOTETomek fue crucial para mejorar la capacidad del modelo de detectar fallos (IsFail=1).



CaracterÃ­sticas como Torque_[Nm] y Tool_wear_[min] son predictoras clave, segÃºn el anÃ¡lisis de correlaciÃ³n.



XGBoost podrÃ­a beneficiarse de ajustes de hiperparÃ¡metros para reducir el sobreajuste.

ğŸ› ï¸ TecnologÃ­as Utilizadas





Entorno: Microsoft Fabric (Workspace: deteccion-fallos, Lakehouse: faultlakehouse).



LibrerÃ­as:





PySpark: Para procesamiento distribuido de datos.



MLflow: Para rastreo y registro de experimentos.



Scikit-learn: Para Random Forest y Logistic Regression.



XGBoost: Para el modelo XGBoost.



SMOTETomek (imblearn): Para balanceo de clases.



Seaborn, Matplotlib: Para visualizaciÃ³n.

ğŸ“‚ Estructura del Repositorio

Ejercicio-7-Deteccion-Fallos/
â”œâ”€â”€ fault_detection.ipynb                        # Notebook con el cÃ³digo completo
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ predictive_maintenance.csv               # Dataset original
â”‚   â”œâ”€â”€ predictive_maintenance_test_data.csv     # Conjunto de prueba
â”‚   â”œâ”€â”€ predictive_maintenance_test_with_predictions.csv  # Predicciones
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ correlation_heatmap.png                  # Matriz de correlaciÃ³n
â”‚   â”œâ”€â”€ feature_histograms.png                   # Histogramas de caracterÃ­sticas
â”‚   â”œâ”€â”€ failure_type_counts.png                  # Conteo de tipos de fallo
â”‚   â”œâ”€â”€ class_balance_counts.png                 # Conteo de clases (desbalanceado)
â”‚   â”œâ”€â”€ balanced_class_counts.png                # Conteo de clases (balanceado)
â”œâ”€â”€ README.md                                    # Este archivo

ğŸš€ Â¿CÃ³mo Reproducir Este Proyecto?





Configura el entorno:





Crea una carpeta deteccion-fallos en Microsoft Fabric.



AÃ±ade un lakehouse (faultlakehouse).



Crea un notebook (fault_detection.ipynb) y vincÃºlalo al lakehouse.



Ejecuta el notebook:





Sigue los bloques de cÃ³digo en orden (carga, EDA, preprocesamiento, entrenamiento, predicciÃ³n).



AsegÃºrate de guardar las grÃ¡ficas generadas.



Descarga los archivos:





Descarga el notebook, dataset, predicciones y grÃ¡ficas siguiendo las instrucciones del bloque 7.



Explora los resultados:





Revisa las mÃ©tricas y grÃ¡ficas para entender el rendimiento del modelo.

ğŸŒŸ ReflexiÃ³n

Este proyecto fue una gran oportunidad para trabajar con datos desbalanceados y aplicar tÃ©cnicas de aprendizaje automÃ¡tico en un escenario de mantenimiento predictivo. El uso de SMOTETomek mejorÃ³ significativamente la capacidad del modelo para detectar fallos, y Random Forest demostrÃ³ ser una opciÃ³n robusta. En el futuro, me gustarÃ­a explorar ajustes de hiperparÃ¡metros para XGBoost y agregar mÃ¡s caracterÃ­sticas al dataset para mejorar aÃºn mÃ¡s el rendimiento.

ğŸ‘¤ Autor: Juan Heriberto Rosas JuÃ¡rez
ğŸ“§ Correo: juanheriberto.rosas@jhrjdata.com
ğŸŒ LinkedIn: Juan Heriberto Rosas JuÃ¡rez
ğŸ¢ OrganizaciÃ³n: Gobierno Digital e InnovaciÃ³n

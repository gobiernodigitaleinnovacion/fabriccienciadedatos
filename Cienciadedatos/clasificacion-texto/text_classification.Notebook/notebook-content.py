# Fabric notebook source

# METADATA ********************

# META {
# META   "kernel_info": {
# META     "name": "synapse_pyspark"
# META   },
# META   "dependencies": {
# META     "lakehouse": {
# META       "default_lakehouse": "b15e35c9-027b-4aca-a5e0-3ec57c19ff19",
# META       "default_lakehouse_name": "textclassificationlakehouse",
# META       "default_lakehouse_workspace_id": "dfe1c7ef-c511-43d8-a794-a1fbbbb49b7c",
# META       "known_lakehouses": [
# META         {
# META           "id": "b15e35c9-027b-4aca-a5e0-3ec57c19ff19"
# META         }
# META       ]
# META     }
# META   }
# META }

# MARKDOWN ********************

# **Bloque 1: Instalaci칩n de librer칤as y configuraci칩n inicial**
# 
# Objetivo: Instalar la librer칤a necesaria (wordcloud), descargar el dataset (blbooksgenre.csv), y configurar MLflow para el rastreo del experimento.

# CELL ********************

# Bloque 1: Instalaci칩n de librer칤as y configuraci칩n inicial
# Instalamos la librer칤a wordcloud, descargamos el dataset y configuramos MLflow.

# Instalar la librer칤a wordcloud
%pip install wordcloud

# Importar librer칤as necesarias
import os
import requests
import time
import mlflow

# Definir par치metros
IS_CUSTOM_DATA = False  # Usaremos datos p칰blicos
DATA_FOLDER = "Files/title-genre-classification"
DATA_FILE = "blbooksgenre.csv"
TEXT_COL = "Title"
LABEL_COL = "annotator_genre"
LABELS = ["Fiction", "Non-fiction"]
EXPERIMENT_NAME = "sample-aisample-textclassification"  # Nombre del experimento en MLflow

# Descargar el dataset y almacenarlo en el lakehouse si no est치 presente
if not IS_CUSTOM_DATA:
    remote_url = "https://synapseaisolutionsa.blob.core.windows.net/public/Title_Genre_Classification"
    fname = "blbooksgenre.csv"
    download_path = f"/lakehouse/default/{DATA_FOLDER}/raw"

    if not os.path.exists("/lakehouse/default"):
        raise FileNotFoundError("Default lakehouse not found, please add a lakehouse and restart the session.")
    os.makedirs(download_path, exist_ok=True)
    if not os.path.exists(f"{download_path}/{fname}"):
        r = requests.get(f"{remote_url}/{fname}", timeout=30)
        with open(f"{download_path}/{fname}", "wb") as f:
            f.write(r.content)
    print("Datos descargados en el lakehouse en Files/title-genre-classification/raw/.")

# Registrar el tiempo de inicio
ts = time.time()

# Configurar MLflow para el rastreo del experimento
mlflow.set_experiment(EXPERIMENT_NAME)
mlflow.autolog(disable=True)  # Desactivar el autologging de MLflow
print("Configuraci칩n de MLflow completada.")

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# MARKDOWN ********************

# **Bloque 2: Carga de datos y an치lisis exploratorio inicial
# **
# Objetivo: Cargar los datos desde el lakehouse, realizar un an치lisis exploratorio inicial, limpiar y transformar los datos, y visualizar nubes de palabras para cada clase.
# 
# Contexto:
# 
# Vamos a cargar el archivo CSV blbooksgenre.csv desde Files/title-genre-classification/raw/.
# Filtraremos y limpiaremos los datos (eliminando duplicados y seleccionando solo las columnas relevantes).
# Tokenizaremos los t칤tulos, eliminaremos stopwords y generaremos nubes de palabras para visualizar las palabras m치s frecuentes en cada clase (ficci칩n y no ficci칩n).

# CELL ********************

# Bloque 2: Carga de datos y an치lisis exploratorio inicial
# Cargamos los datos, los limpiamos, tokenizamos y visualizamos nubes de palabras.

import numpy as np
from itertools import chain
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import seaborn as sns
import pyspark.sql.functions as F
from pyspark.ml import Pipeline
from pyspark.ml.feature import Tokenizer, StopWordsRemover, StringIndexer, Word2Vec

# Cargar los datos desde el lakehouse
raw_df = spark.read.csv(f"{DATA_FOLDER}/raw/{DATA_FILE}", header=True, inferSchema=True)

# Mostrar las primeras filas del dataset
print("Primeras filas del dataset:")
display(raw_df.limit(20))

# Limpiar y transformar los datos
# Seleccionar columnas relevantes, filtrar etiquetas v치lidas y eliminar duplicados
df = (
    raw_df.select([TEXT_COL, LABEL_COL])
    .where(F.col(LABEL_COL).isin(LABELS))
    .dropDuplicates([TEXT_COL])
    .cache()
)

# Mostrar las primeras filas del dataset limpio
print("Primeras filas del dataset limpio:")
display(df.limit(20))

# Balancear las clases
from synapse.ml.stages import ClassBalancer
cb = ClassBalancer().setInputCol(LABEL_COL)
df = cb.fit(df).transform(df)

# Mostrar las primeras filas del dataset balanceado
print("Primeras filas del dataset balanceado:")
display(df.limit(20))

# Tokenizar y eliminar stopwords
tokenizer = Tokenizer(inputCol=TEXT_COL, outputCol="tokens")
stopwords_remover = StopWordsRemover(inputCol="tokens", outputCol="filtered_tokens")
pipeline = Pipeline(stages=[tokenizer, stopwords_remover])
token_df = pipeline.fit(df).transform(df)

# Mostrar las primeras filas del dataset tokenizado
print("Primeras filas del dataset tokenizado:")
display(token_df.limit(20))

# Generar nubes de palabras para cada clase
for label in LABELS:
    tokens = (
        token_df.where(F.col(LABEL_COL) == label)
        .select(F.explode("filtered_tokens").alias("token"))
        .where(F.col("token").rlike(r"^\w+$"))
    )

    top50_tokens = (
        tokens.groupBy("token").count().orderBy(F.desc("count")).limit(50).collect()
    )

    # Generar una nube de palabras
    wordcloud = WordCloud(
        scale=10,
        background_color="white",
        random_state=42,
    ).generate_from_frequencies(dict(top50_tokens))

    # Mostrar la nube de palabras
    plt.figure(figsize=(10, 10))
    plt.title(label, fontsize=20)
    plt.axis("off")
    plt.imshow(wordcloud, interpolation="bilinear")
    plt.show()
    print(f"Nube de palabras para '{label}' generada. Gu치rdala manualmente como 'wordcloud_{label.lower()}.png'.")

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# MARKDOWN ********************

# **Bloque 3: Preparaci칩n de datos y vectorizaci칩n**
# 
# Objetivo: Vectorizar los t칤tulos usando word2vec, preparar los datos para entrenamiento y dividirlos en conjuntos de entrenamiento y prueba.
# 
# Contexto:
# 
# Usaremos word2vec para convertir los tokens filtrados en vectores de caracter칤sticas.
# Convertiremos las etiquetas (Fiction, Non-fiction) a 칤ndices num칠ricos.
# Dividiremos el dataset en conjuntos de entrenamiento (80%) y prueba (20%).

# CELL ********************

# Bloque 3: Preparaci칩n de datos y vectorizaci칩n
# Vectorizamos los t칤tulos con word2vec y preparamos los datos para entrenamiento.

# Definir hiperpar치metros
word2vec_size = 128  # Tama침o del vector para cada palabra
min_word_count = 3   # M칤nimo n칰mero de apariciones de una palabra para ser considerada

# Transformar etiquetas y vectorizar los t칤tulos
label_indexer = StringIndexer(inputCol=LABEL_COL, outputCol="labelIdx")
vectorizer = Word2Vec(
    vectorSize=word2vec_size,
    minCount=min_word_count,
    inputCol="filtered_tokens",
    outputCol="features",
)

# Construir el pipeline
pipeline = Pipeline(stages=[label_indexer, vectorizer])
vec_df = (
    pipeline.fit(token_df)
    .transform(token_df)
    .select([TEXT_COL, LABEL_COL, "features", "labelIdx", "weight"])
)

# Mostrar las primeras filas del dataset vectorizado
print("Primeras filas del dataset vectorizado:")
display(vec_df.limit(20))

# Dividir el dataset en entrenamiento y prueba
(train_df, test_df) = vec_df.randomSplit((0.8, 0.2), seed=42)
print("Dataset dividido: 80% entrenamiento, 20% prueba.")

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# MARKDOWN ********************

# **Bloque 4: Entrenamiento y evaluaci칩n del modelo**
# 
# Objetivo: Entrenar un modelo de regresi칩n log칤stica con validaci칩n cruzada, evaluar su desempe침o y registrar los experimentos en MLflow.
# 
# Contexto:
# 
# Definiremos un modelo de regresi칩n log칤stica y construiremos una cuadr칤cula de hiperpar치metros para optimizaci칩n.
# Usaremos validaci칩n cruzada con 3 pliegues (k_folds = 3) para seleccionar el mejor modelo.
# Evaluaremos el modelo en el conjunto de prueba y registraremos m칠tricas y modelos en MLflow.

# CELL ********************

# Bloque 4: Entrenamiento y evaluaci칩n del modelo
# Entrenamos un modelo de regresi칩n log칤stica con validaci칩n cruzada y registramos en MLflow.

from pyspark.ml.classification import LogisticRegression
from pyspark.ml.tuning import CrossValidator, ParamGridBuilder
from pyspark.ml.evaluation import BinaryClassificationEvaluator

# Definir hiperpar치metros
max_iter = 10  # M치ximo n칰mero de iteraciones para la regresi칩n log칤stica
k_folds = 3    # N칰mero de pliegues para validaci칩n cruzada

# Construir el modelo de regresi칩n log칤stica
lr = (
    LogisticRegression()
    .setMaxIter(max_iter)
    .setFeaturesCol("features")
    .setLabelCol("labelIdx")
    .setWeightCol("weight")
)

# Construir una cuadr칤cula de hiperpar치metros para b칰squeda
param_grid = (
    ParamGridBuilder()
    .addGrid(lr.regParam, [0.03, 0.1])
    .addGrid(lr.elasticNetParam, [0.0, 0.1])
    .build()
)

# Definir el evaluador (clasificaci칩n binaria)
evaluator = BinaryClassificationEvaluator(labelCol="labelIdx", weightCol="weight")

# Construir el validador cruzado
crossval = CrossValidator(
    estimator=lr,
    estimatorParamMaps=param_grid,
    evaluator=evaluator,
    numFolds=k_folds,
    collectSubModels=True,
)

# Funci칩n para evaluar el modelo
def evaluate(model, df):
    log_metric = {}
    prediction = model.transform(df)
    for metric in ["areaUnderROC", "areaUnderPR"]:
        value = evaluator.evaluate(prediction, {evaluator.metricName: metric})
        log_metric[metric] = value
        print(f"{metric}: {value:.4f}")
    return prediction, log_metric

# Entrenar y evaluar el modelo con MLflow
with mlflow.start_run(run_name="lr"):
    models = crossval.fit(train_df)
    best_metrics = {"areaUnderROC": 0, "areaUnderPR": 0}
    best_index = 0
    for idx, model in enumerate(models.subModels[0]):
        with mlflow.start_run(nested=True, run_name=f"lr_{idx}") as run:
            print(f"\nEvaluando en datos de prueba:")
            print(f"subModel No. {idx + 1}")
            prediction, log_metric = evaluate(model, test_df)

            if log_metric["areaUnderROC"] > best_metrics["areaUnderROC"]:
                best_metrics = log_metric
                best_index = idx

            print("Registrando modelo")
            mlflow.spark.log_model(
                model,
                f"{EXPERIMENT_NAME}-lrmodel",
                registered_model_name=f"{EXPERIMENT_NAME}-lrmodel",
                dfs_tmpdir="Files/spark",
            )

            print("Registrando m칠tricas")
            mlflow.log_metrics(log_metric)

            print("Registrando par치metros")
            mlflow.log_params(
                {
                    "word2vec_size": word2vec_size,
                    "min_word_count": min_word_count,
                    "max_iter": max_iter,
                    "k_folds": k_folds,
                    "DATA_FILE": DATA_FILE,
                }
            )

    # Registrar el mejor modelo en el run padre
    mlflow.spark.log_model(
        models.subModels[0][best_index],
        f"{EXPERIMENT_NAME}-lrmodel",
        registered_model_name=f"{EXPERIMENT_NAME}-lrmodel",
        dfs_tmpdir="Files/spark",
    )
    mlflow.log_metrics(best_metrics)
    mlflow.log_params(
        {
            "word2vec_size": word2vec_size,
            "min_word_count": min_word_count,
            "max_iter": max_iter,
            "k_folds": k_folds,
            "DATA_FILE": DATA_FILE,
        }
    )

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# MARKDOWN ********************

# **Bloque 5: Generaci칩n de predicciones y guardado**
# 
# Objetivo: Usar el mejor modelo para generar predicciones por lotes, guardarlas en el lakehouse, y calcular el tiempo total de ejecuci칩n del notebook.
# 
# Contexto:
# 
# Usaremos el mejor modelo (subModel No. 1, versi칩n 2 seg칰n el tutorial, pero versi칩n 5 en tu caso debido a ejecuciones previas) para realizar predicciones por lotes.
# Guardaremos las predicciones en el lakehouse.
# Calcularemos el tiempo total de ejecuci칩n del notebook.

# CELL ********************

# Bloque 5: Generaci칩n de predicciones y guardado
# Usamos el mejor modelo para generar predicciones por lotes y las guardamos en el lakehouse.

# Cargar el mejor modelo (versi칩n 5: subModel No. 1 con areaUnderROC = 0.7698)
model_uri = f"models:/{EXPERIMENT_NAME}-lrmodel/5"
loaded_model = mlflow.spark.load_model(model_uri, dfs_tmpdir="Files/spark")

# Generar predicciones por lotes
batch_predictions = loaded_model.transform(test_df)

# Mostrar las primeras filas de las predicciones
print("Primeras filas de las predicciones por lotes (mejor modelo):")
display(batch_predictions.limit(5))

# Guardar las predicciones en el lakehouse
batch_predictions.write.format("delta").mode("overwrite").save(
    f"{DATA_FOLDER}/predictions/batch_predictions"
)
print("Predicciones guardadas en abfss://Fabric@onelake.dfs.fabric.microsoft.com/textclassificationlakehouse.Lakehouse/Files/title-genre-classification/predictions/batch_predictions.")

# Calcular el tiempo total de ejecuci칩n
print(f"Tiempo total de ejecuci칩n: {int(time.time() - ts)} segundos.")

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# MARKDOWN ********************

# **Bloque 6: Conclusiones y publicaci칩n**
# 
# Objetivo: Resumir los hallazgos del proyecto, descargar los archivos necesarios (notebook, dataset, predicciones, gr치ficos), crear un README.md para este ejercicio, y preparar un post para LinkedIn.
# 
# Contexto:
# 
# Resumiremos los resultados clave del ejercicio, incluyendo estad칤sticas del dataset, m칠tricas de los modelos, y las visualizaciones generadas.
# Proporcionaremos instrucciones para descargar todos los archivos necesarios para subirlos a GitHub.
# Crearemos un README.md espec칤fico para este ejercicio, destacando el proceso, los resultados y las lecciones aprendidas.
# Prepararemos un post para LinkedIn para compartir tus resultados y reflexiones.

# CELL ********************

# Bloque 6: Conclusiones y publicaci칩n
# Resumimos los hallazgos, descargamos archivos y preparamos la publicaci칩n en GitHub y LinkedIn.

# Resumen de hallazgos
print("### Resumen de Hallazgos ###")
print("- **Tama침o del dataset**: Datos de t칤tulos de libros de la British Library, con etiquetas de g칠nero (Fiction/Non-fiction).")
print("- **Patrones observados**: Las nubes de palabras muestran palabras clave distintivas para cada g칠nero (por ejemplo, 'poem', 'novel' en Fiction; 'history', 'study' en Non-fiction).")
print("- **Modelos entrenados**: Regresi칩n log칤stica con word2vec, optimizada con validaci칩n cruzada (4 combinaciones de hiperpar치metros).")
print("- **Mejor modelo**: regParam=0.03, elasticNetParam=0.0, con areaUnderROC de 0.7698 y areaUnderPR de 0.7115.")
print("- **Conclusi칩n**: El modelo tiene un desempe침o aceptable, pero podr칤a beneficiarse de m치s datos o ajustes en los hiperpar치metros de word2vec.")

# Instrucciones para descargar archivos
# Descargar el notebook text_classification.ipynb
print("Instrucciones para descargar el notebook:")
print("1. Ve a *Workspace > Fabric > clasificacion-texto > textclassificationlakehouse > Notebooks/*.")
print("2. Abre el notebook `text_classification.ipynb`.")
print("3. Haz clic en *File > Download* para descargar el notebook a tu m치quina local (por ejemplo, a C:\\Users\\hello\\Downloads\\).")

# Descargar el dataset desde el lakehouse
print("Instrucciones para descargar el dataset:")
print("1. Ve a *Workspace > Fabric > clasificacion-texto > textclassificationlakehouse > Files/title-genre-classification/raw/*.")
print("2. Haz clic derecho sobre `blbooksgenre.csv` y selecciona *Download*.")
print("3. Gu치rdalo en tu m치quina local (por ejemplo, a C:\\Users\\hello\\Downloads\\).")

# Descargar las predicciones desde el lakehouse
print("Instrucciones para descargar las predicciones:")
print("1. Ve a *Workspace > Fabric > clasificacion-texto > textclassificationlakehouse > Files/title-genre-classification/predictions/*.")
print("2. Descarga la carpeta `batch_predictions` (puede aparecer como archivos individuales como `part-00000`, etc.).")
print("3. Renombra la carpeta o los archivos como `batch_predictions.csv` en tu m치quina local para mayor claridad.")

# Nota sobre las gr치ficas ya guardadas
print("Ya tienes las gr치ficas guardadas: wordcloud_fiction.png, wordcloud_nonfiction.png.")

# Crear un README.md para el ejercicio
readme_content = """# Ejercicio 5: Clasificaci칩n de Texto

Desarroll칠 un modelo de clasificaci칩n de texto para determinar el g칠nero de libros (ficci칩n o no ficci칩n) basado en sus t칤tulos, utilizando datos de la British Library. Implement칠 el modelo en Microsoft Fabric con Spark y MLflow, empleando word2vec para vectorizar los t칤tulos y regresi칩n log칤stica para la clasificaci칩n.

## Proceso
- **Carga y limpieza**: Cargu칠 el dataset (`blbooksgenre.csv`), elimin칠 duplicados y balance칠 las clases.  
- **An치lisis exploratorio**: Gener칠 nubes de palabras para identificar palabras clave por g칠nero.  
- **Modelado**: Entren칠 un modelo de regresi칩n log칤stica con word2vec, optimizando hiperpar치metros mediante validaci칩n cruzada.  
- **Evaluaci칩n**: El mejor modelo logr칩 un areaUnderROC de 0.7698 y un areaUnderPR de 0.7115.  
- **Predicciones**: Gener칠 predicciones por lotes y las guard칠 en el lakehouse.  

## Resultados
- **Patrones**: Palabras como 'poem' y 'novel' predominan en Fiction; 'history' y 'study' en Non-fiction.  
- **Mejor modelo**: `regParam=0.03`, `elasticNetParam=0.0`, con areaUnderROC de 0.7698 y areaUnderPR de 0.7115.  
- **Conclusi칩n**: El modelo tiene un desempe침o aceptable, pero podr칤a mejorarse con m치s datos o ajustes en los par치metros de word2vec.

## Tecnolog칤as utilizadas
- Python, Microsoft Fabric, Spark, MLflow, Word2Vec, Logistic Regression, WordCloud, Seaborn, Matplotlib.  

## Archivos disponibles
- [Notebook](text_classification.ipynb)  
- [Gr치ficas](results/)
"""

# Guardar el README.md localmente
with open("/tmp/README_text_classification.md", "w") as f:
    f.write(readme_content)
print("README_text_classification.md guardado localmente en /tmp/. Desc치rgalo manualmente desde la interfaz de Fabric y ren칩mbralo como README.md.")

# Preparar post para LinkedIn
linkedin_post = """춰Nuevo proyecto de ciencia de datos! 游닄 Desarroll칠 un modelo de clasificaci칩n de texto en Microsoft Fabric para determinar el g칠nero de libros (ficci칩n o no ficci칩n) basado en sus t칤tulos, utilizando datos de la British Library. Algunos hallazgos clave:

- Dataset: T칤tulos de libros con etiquetas de g칠nero, analizados con nubes de palabras.
- Modelos: Regresi칩n log칤stica con word2vec, logrando un areaUnderROC de 0.7698.
- Conclusi칩n: El modelo es prometedor, pero hay espacio para mejorar con m치s datos o ajustes.

Explora el c칩digo y an치lisis en mi GitHub: [enlace al repositorio].

游녻 Juan Heriberto Rosas Ju치rez  
游닎 juanheriberto.rosas@jhrjdata.com  
游깷 https://www.linkedin.com/in/juan-heriberto-rosas-ju%C3%A1rez-6a78a82a2/  
游끽 Gobierno Digital e Innovaci칩n: https://www.gobiernodigitaleinnovacion.com/  
#DataScience #MicrosoftFabric #TextClassification
"""

# Guardar el post para LinkedIn localmente
with open("/tmp/linkedin_post_text_classification.txt", "w") as f:
    f.write(linkedin_post)
print("Post para LinkedIn guardado localmente en /tmp/linkedin_post_text_classification.txt. Desc치rgalo manualmente desde la interfaz de Fabric.")

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

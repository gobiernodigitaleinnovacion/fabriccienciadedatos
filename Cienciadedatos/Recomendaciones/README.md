Ejercicio 2: Sistema de Recomendaci√≥n de Libros (An√°lisis Comparativo) üìö

En este proyecto, desarroll√© un sistema de recomendaci√≥n de libros basado en las preferencias de los usuarios, utilizando un modelo de filtrado colaborativo con ALS (Alternating Least Squares) en Microsoft Fabric. Realic√© dos experimentos: un experimento inicial para establecer una l√≠nea base y un experimento mejorado para optimizar el rendimiento. A continuaci√≥n, detallo el proceso t√©cnico, los resultados, un an√°lisis cr√≠tico de los modelos y las lecciones aprendidas.

üéØ Objetivo
El objetivo principal fue construir un sistema de recomendaci√≥n que sugiera libros a los usuarios bas√°ndose en sus calificaciones hist√≥ricas, utilizando el dataset Book-Crossing. Compar√© dos enfoques para evaluar c√≥mo las mejoras en el preprocesamiento y los hiperpar√°metros afectan el rendimiento del modelo ALS, con el fin de generar recomendaciones m√°s precisas y √∫tiles.

üìä Dataset
El dataset Book-Crossing contiene tres archivos principales:

Books.csv: Informaci√≥n de libros (ISBN, t√≠tulo, autor, etc.).
Ratings.csv: Calificaciones de usuarios (User-ID, ISBN, rating de 0 a 10).
Users.csv: Datos de usuarios (User-ID, ubicaci√≥n, edad).

Estad√≠sticas iniciales:

Usuarios: 278,858 usuarios distintos.
Libros: 271,360 libros distintos.
Interacciones usuario-libro: 1,031,136 calificaciones.

Desaf√≠os:

Alta dispersi√≥n del dataset (99.7465%), lo que dificulta encontrar patrones significativos.
Presencia de calificaciones impl√≠citas (rating=0) que requieren un manejo especial.

üõ†Ô∏è Experimentos
Experimento Inicial
Proceso

Carga y limpieza:
Cargu√© los datos con Spark desde Books.csv, Ratings.csv, y Users.csv.
Elimin√© duplicados y valores nulos para garantizar la calidad de los datos.
Us√© una muestra de 5,000 filas para acelerar el entrenamiento.


Visualizaci√≥n:
Gener√© gr√°ficos exploratorios para identificar patrones:
Autores con m√°s libros publicados.
Libros m√°s populares seg√∫n las calificaciones.




Ingenier√≠a de caracter√≠sticas:
Transform√© User-ID e ISBN en √≠ndices enteros (_user_id, _item_id) para el modelo ALS.


Modelado:
Entren√© un modelo ALS con hiperpar√°metros: rank=64, regParam=[0.01, 0.1], maxIter=1.
Us√© MLflow para rastrear los experimentos.


Evaluaci√≥n:
Calcul√© m√©tricas: RMSE, MAE, R¬≤ y varianza explicada.


An√°lisis:
Gener√© las top 10 recomendaciones de libros para cada usuario.



Resultados

Estad√≠sticas:
Total de usuarios: 278,858.
Total de libros: 271,360.
Total de interacciones usuario-libro: 1,031,136.
Dispersi√≥n del dataset: 99.7465% (muy alta).


Rendimiento del modelo ALS (mejor submodelo):
RMSE: 4.7458 (error promedio alto).
MAE: 4.4646 (error absoluto promedio tambi√©n alto).
R¬≤: -14.9927 (negativo, indica que el modelo no explica los datos).
Varianza explicada: 21.1474.


Top libros m√°s populares:
"Wild Animus" (2,502 calificaciones).
"The Lovely Bones: A Novel" (1,295 calificaciones).
"The Da Vinci Code" (883 calificaciones).


Top recomendaciones generadas:
"Lasher: Lives of the Mayfair Witches".
"The Da Vinci Code".



An√°lisis inicial
El modelo inicial mostr√≥ un rendimiento pobre (R¬≤ negativo), principalmente debido a la alta dispersi√≥n del dataset y la muestra limitada de datos. Esto motiv√≥ un segundo experimento para abordar estas limitaciones.

Experimento Mejorado
Proceso
Para mejorar los resultados, realic√© los siguientes ajustes:

Carga y limpieza:
Filtr√© usuarios y libros con menos de 5 interacciones para reducir la dispersi√≥n y mejorar la calidad de los datos.
Us√© el dataset completo (sin muestreo) para aprovechar m√°s interacciones.


Modelado:
Ajust√© los hiperpar√°metros: rank=[16, 32], regParam=[0.01, 0.1], maxIter=5.
Continu√© usando MLflow para rastrear los experimentos.


Evaluaci√≥n y an√°lisis:
Gener√© nuevas recomendaciones y compar√© m√©tricas con el experimento inicial.



Resultados

Estad√≠sticas despu√©s del filtrado:
Total de usuarios: 22,072 (filtrados para mayor calidad).
Total de libros: 40,909 (filtrados para mayor calidad).
Total de interacciones usuario-libro: 600,148.
Dispersi√≥n del dataset: 99.9326% (ligeramente reducida).


Rendimiento del modelo ALS (mejor submodelo):
RMSE: 2.5447 (mejorado respecto al experimento inicial: 4.7458).
MAE: 1.9916 (mejorado respecto al experimento inicial: 4.4646).
R¬≤: -1.0012 (negativo, pero mejorado respecto al experimento inicial: -14.9927).
Varianza explicada: 5.0675 (menor que el experimento inicial: 21.1474).


Top libros m√°s populares:
"Wild Animus" (1,686 calificaciones).
"The Lovely Bones: A Novel" (981 calificaciones).
"The Da Vinci Code" (722 calificaciones).


Top recomendaciones generadas:
"The Elementary Particles".
"The Pugilist at Rest".
"The Da Vinci Code".




üìâ An√°lisis Cr√≠tico: ¬øPor qu√© los modelos no son adecuados?
A pesar de las mejoras en el segundo experimento, ambos modelos tienen un R¬≤ negativo, lo que indica que no explican bien los datos y son peores que una predicci√≥n simple basada en la media de las calificaciones. Las razones principales son:

Alta dispersi√≥n del dataset:
Incluso despu√©s del filtrado, la dispersi√≥n sigue siendo muy alta (99.9326%), lo que dificulta que ALS encuentre patrones significativos.


Limitaciones del modelo ALS:
ALS puede no ser el mejor enfoque para datasets tan dispersos. Modelos alternativos, como redes neuronales (por ejemplo, embeddings) o enfoques basados en contenido (usando metadatos de libros), podr√≠an ser m√°s efectivos.


Interacciones impl√≠citas no aprovechadas:
En el experimento mejorado, us√© implicitPrefs=False para depuraci√≥n, lo que limit√≥ la capacidad del modelo para manejar calificaciones impl√≠citas (rating=0). Configurar implicitPrefs=True podr√≠a haber mejorado los resultados.


Hiperpar√°metros y datos:
Aunque ajust√© los hiperpar√°metros, las configuraciones probadas (rank, regParam, maxIter) podr√≠an no ser √≥ptimas. Adem√°s, el volumen de datos sigue siendo insuficiente para un dataset tan disperso.



üåü Valor del Proyecto
Aunque los modelos no son adecuados para predicciones precisas debido a su R¬≤ negativo, este proyecto tiene un valor significativo como ejercicio de aprendizaje:

Exploraci√≥n y limpieza de datos:
Aprend√≠ a manejar datasets dispersos, filtrar datos irrelevantes y reducir la dispersi√≥n para mejorar la calidad de los datos.


Visualizaci√≥n y an√°lisis:
Los gr√°ficos generados (como los libros m√°s populares) son √∫tiles para entender patrones en los datos, incluso sin un modelo efectivo.


Generaci√≥n de recomendaciones:
A pesar de las m√©tricas pobres, las recomendaciones generadas (como "The Da Vinci Code") identifican libros populares y relevantes, lo que puede ser √∫til en un contexto exploratorio para usuarios.


Uso de herramientas modernas:
Gan√© experiencia con Microsoft Fabric, Spark, MLflow, Pandas, Seaborn y Matplotlib, herramientas clave en ciencia de datos.


Lecciones aprendidas:
Entend√≠ las limitaciones de ALS en datasets dispersos y la importancia de manejar datos impl√≠citos, lo que me ayudar√° a dise√±ar mejores sistemas de recomendaci√≥n en el futuro.



üõ†Ô∏è Tecnolog√≠as Utilizadas

Entorno: Microsoft Fabric (Workspace: recomendaciones-libros, Lakehouse: booklakehouse).
Librer√≠as:
PySpark: Para procesamiento distribuido de datos.
MLflow: Para rastreo y registro de experimentos.
Pandas: Para manipulaci√≥n de datos.
Seaborn, Matplotlib: Para visualizaci√≥n.



üìÇ Estructura del Repositorio
Ejercicio-2-Recomendaciones/
‚îú‚îÄ‚îÄ recommendation_system.ipynb                   # Notebook del experimento inicial
‚îú‚îÄ‚îÄ recommendation_system_improved.ipynb          # Notebook del experimento mejorado
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ Books.csv                                 # Datos de libros
‚îÇ   ‚îú‚îÄ‚îÄ Ratings.csv                               # Calificaciones de usuarios
‚îÇ   ‚îú‚îÄ‚îÄ Users.csv                                 # Datos de usuarios
‚îú‚îÄ‚îÄ results/
‚îÇ   ‚îú‚îÄ‚îÄ initial_popular_books.png                 # Gr√°fica de libros populares (experimento inicial)
‚îÇ   ‚îú‚îÄ‚îÄ initial_author_distribution.png           # Distribuci√≥n de autores (experimento inicial)
‚îÇ   ‚îú‚îÄ‚îÄ improved_popular_books.png                # Gr√°fica de libros populares (experimento mejorado)
‚îÇ   ‚îú‚îÄ‚îÄ improved_author_distribution.png          # Distribuci√≥n de autores (experimento mejorado)
‚îú‚îÄ‚îÄ README.md                                     # Este archivo

üöÄ ¬øC√≥mo Reproducir Este Proyecto?

Configura el entorno:
Crea una carpeta recomendaciones-libros en Microsoft Fabric.
A√±ade un lakehouse (booklakehouse).
Crea dos notebooks (recommendation_system.ipynb y recommendation_system_improved.ipynb) y vinc√∫lalos al lakehouse.


Ejecuta los notebooks:
Sigue los bloques de c√≥digo en cada notebook (carga, EDA, modelado, evaluaci√≥n).
Aseg√∫rate de guardar las gr√°ficas generadas.


Descarga los archivos:
Descarga los notebooks, datasets y gr√°ficas siguiendo las instrucciones en cada notebook.


Explora los resultados:
Revisa las m√©tricas (RMSE, MAE, R¬≤) y las gr√°ficas para entender el rendimiento de los modelos.



üåü Reflexi√≥n
Este proyecto fue una valiosa oportunidad para explorar los desaf√≠os de los sistemas de recomendaci√≥n con datasets dispersos. Aunque ALS no fue adecuado para este caso, el proceso me permiti√≥ aprender t√©cnicas de preprocesamiento, manejo de dispersi√≥n y evaluaci√≥n de modelos. En el futuro, planeo explorar modelos h√≠bridos (filtrado colaborativo + contenido) o enfoques basados en redes neuronales para mejorar las recomendaciones.
Ver notebook del Experimento Inicial | Ver gr√°ficos del Experimento InicialVer notebook del Experimento Mejorado | Ver gr√°ficos del Experimento Mejorado
üë§ Autor: Juan Heriberto Rosas Ju√°rezüìß Correo: juanheriberto.rosas@jhrjdata.comüåê LinkedIn: Juan Heriberto Rosas Ju√°rezüè¢ Organizaci√≥n: Gobierno Digital e Innovaci√≥n


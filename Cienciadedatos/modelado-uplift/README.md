Ejercicio 6: Modelado de Uplift para Identificar Persuadables üìà
En este proyecto, desarroll√© un modelo de uplift utilizando un T-Learner para identificar usuarios "persuadables" que responden positivamente a un tratamiento (publicidad), empleando el dataset de Criteo. Implement√© el flujo de trabajo en Microsoft Fabric con Apache Spark y MLflow, inicialmente intentando usar LightGBMClassifier, pero debido a problemas de compatibilidad, opt√© por LogisticRegression de PySpark ML. A continuaci√≥n, detallo el proceso t√©cnico, los resultados obtenidos y las lecciones aprendidas.
üéØ Objetivo
El objetivo principal fue construir un modelo de uplift para estimar el efecto incremental de un tratamiento (publicidad) en el comportamiento de los usuarios, espec√≠ficamente en su probabilidad de visitar una tienda online. El modelo clasifica a los usuarios en grupos como "persuadables" (aquellos que responden positivamente al tratamiento), optimizando as√≠ las estrategias de marketing. Este proyecto forma parte de una serie de ejercicios de ciencia de datos realizados en Microsoft Fabric, demostrando un flujo completo de modelado de uplift.
üìä Dataset
El dataset utilizado proviene de Criteo AI Lab y contiene 13M de registros, cada uno representando a un usuario. Incluye las siguientes columnas:

f0 a f11: 12 caracter√≠sticas num√©ricas (valores flotantes densos) que describen a los usuarios.
treatment: Indicador binario (1 = usuario expuesto al tratamiento, 0 = control).
visit: Etiqueta binaria (1 = usuario visit√≥ la tienda online, 0 = no visit√≥).
conversion: Etiqueta binaria (1 = usuario realiz√≥ una compra, 0 = no compr√≥).
exposure: Indicador de exposici√≥n (no utilizado en este an√°lisis).

Citaci√≥n requerida:
@inproceedings{Diemert2018,
  author = {{Diemert Eustache, Betlei Artem} and Renaudin, Christophe and Massih-Reza, Amini},
  title={A Large Scale Benchmark for Uplift Modeling},
  publisher = {ACM},
  booktitle = {Proceedings of the AdKDD and TargetAd Workshop, KDD, London, United Kingdom, August, 20, 2018},
  year = {2018}
}

Desaf√≠os:

Desbalance entre los grupos de tratamiento (85% tratamiento, ~15% control) y tasas bajas de visita (4.7%) y conversi√≥n (~0.29%).
Problemas de compatibilidad con LightGBMClassifier en SynapseML, lo que llev√≥ al uso de LogisticRegression.

üõ†Ô∏è Proceso T√©cnico
1. Carga y Preprocesamiento de Datos

Carga: Descargu√© el dataset (criteo-research-uplift-v2.1.csv, 13M filas) desde una URL p√∫blica y lo almacen√© en el lakehouse de Microsoft Fabric (upliftlakehouse) en la ruta Files/uplift-modelling/raw/.
Preprocesamiento:
Convert√≠ las columnas de caracter√≠sticas (f0 a f11) a tipo double para asegurar consistencia num√©rica.
Utilic√© VectorAssembler de PySpark ML para combinar las columnas f0 a f11 en una √∫nica columna de caracter√≠sticas features (vector).



2. An√°lisis Exploratorio de Datos (EDA)

Estad√≠sticas generales:
~4.7% de los usuarios visitaron la tienda online.
~0.29% de los usuarios convirtieron (realizaron una compra).
~6.2% de los visitantes convirtieron.


Estad√≠sticas por grupo de tratamiento:
Tratamiento (treatment=1): 4.85% visitaron, 0.31% convirtieron, 6.36% de los visitantes convirtieron.
Control (treatment=0): 3.82% visitaron, 0.19% convirtieron, 5.07% de los visitantes convirtieron.
Efecto del tratamiento: Mejora la tasa de visitas en ~1% y la conversi√≥n de visitantes en ~1.3%.



3. Preparaci√≥n de Datos para el Modelo

Vectorizaci√≥n: Us√© VectorAssembler para crear la columna features a partir de f0 a f11.
Divisi√≥n del dataset: Divid√≠ el dataset en entrenamiento (80%, ~11.18M filas) y prueba (20%, ~2.80M filas).
Separaci√≥n de grupos:
Tratamiento (treatment_train_df): 9.5M filas (85%).
Control (control_train_df): 1.7M filas (15%).



4. Entrenamiento del Modelo T-Learner

Modelo: Implement√© un T-Learner con LogisticRegression de PySpark ML (debido a problemas con LightGBMClassifier):
Configuraci√≥n: maxIter=100, regParam=0.01, elasticNetParam=0.0 (regularizaci√≥n L2).
Entren√© dos modelos:
Modelo de tratamiento: Sobre treatment_train_df (~9.5M filas).
Modelo de control: Sobre control_train_df (~1.7M filas).




Registro: Los modelos se registraron en MLflow bajo los nombres aisample-upliftmodelling-treatmentmodel y aisample-upliftmodelling-controlmodel.

5. Predicci√≥n y C√°lculo del Uplift

Predicciones: Us√© ambos modelos para predecir la probabilidad de visita (visit) en el conjunto de prueba.
Uplift predicho: Calcul√© pred_uplift como la diferencia entre la probabilidad predicha por el modelo de tratamiento (treatment_pred) y el modelo de control (control_pred).
Resultados:
Valores de pred_uplift entre 0.0022 y 0.0028, indicando un efecto modesto del tratamiento.



6. Evaluaci√≥n y Curva de Uplift

Curva de uplift:
Orden√© los usuarios por pred_uplift (descendente) y calcul√© el uplift acumulado (group_uplift) para diferentes proporciones de la poblaci√≥n.
Visualic√© la curva de uplift, mostrando que el top 20% de la poblaci√≥n (persuadables) maximiza el uplift.
La gr√°fica se guard√≥ como UpliftCurve.png en MLflow.


Punto de corte: Identifiqu√© un cutoff_score para el top 20%, registrado en MLflow.

üìà Resultados y Conclusiones

Uplift predicho:
Los valores de pred_uplift oscilan entre 0.0022 y 0.0028, reflejando un efecto modesto del tratamiento, consistente con el an√°lisis exploratorio (~1% de mejora en visitas).


Curva de uplift:
El top 20% de la poblaci√≥n (ordenada por uplift predicho) maximiza el uplift, identificando a los "persuadables".


Lecciones aprendidas:
Compatibilidad: Problemas con LightGBMClassifier en SynapseML (duplicidad de nombres de columnas internas) me llevaron a usar LogisticRegression. Esto sugiere la necesidad de verificar la compatibilidad de las bibliotecas en entornos distribuidos como Fabric.
Uplift modesto: El uplift predicho es peque√±o, lo que podr√≠a deberse a las tasas bajas de visita en el dataset. Modelos m√°s complejos (como LightGBM, si se resuelven los problemas) o caracter√≠sticas adicionales podr√≠an mejorar los resultados.
Escalabilidad: El procesamiento de 13M de registros en Spark fue eficiente, pero el desbalance entre los grupos de tratamiento y control (~85%/15%) requiere un manejo cuidadoso.



üõ†Ô∏è Tecnolog√≠as Utilizadas

Entorno: Microsoft Fabric (Workspace: modelado-uplift, Lakehouse: upliftlakehouse).
Librer√≠as:
PySpark: Para procesamiento distribuido de datos.
MLflow: Para rastreo y registro de experimentos.
LogisticRegression (PySpark ML): Para modelado.
VectorAssembler (PySpark ML): Para preprocesamiento de caracter√≠sticas.
Matplotlib: Para visualizaci√≥n de la curva de uplift.
Python: Lenguaje principal.



üìÇ Estructura del Repositorio
Ejercicio-6-Modelado-Uplift/
‚îú‚îÄ‚îÄ uplift_modeling.ipynb                # Notebook con el c√≥digo completo
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ criteo-research-uplift-v2.1.csv  # Dataset original
‚îÇ   ‚îú‚îÄ‚îÄ batch_predictions_treatment_control.csv  # Predicciones generadas
‚îú‚îÄ‚îÄ results/
‚îÇ   ‚îú‚îÄ‚îÄ UpliftCurve.png                  # Curva de uplift
‚îú‚îÄ‚îÄ README.md                            # Este archivo

üöÄ ¬øC√≥mo Reproducir Este Proyecto?

Configura el entorno:
Crea una carpeta modelado-uplift en Microsoft Fabric.
A√±ade un lakehouse (upliftlakehouse).
Crea un notebook (uplift_modeling.ipynb) y vinc√∫lalo al lakehouse.


Ejecuta el notebook:
Sigue los bloques de c√≥digo en orden (carga, EDA, preprocesamiento, entrenamiento, predicci√≥n, evaluaci√≥n).
Aseg√∫rate de guardar la gr√°fica generada (UpliftCurve.png).


Descarga los archivos:
Descarga el notebook, el dataset, las predicciones y la gr√°fica siguiendo las instrucciones del bloque 7.


Explora los resultados:
Revisa la curva de uplift y el cutoff_score para identificar persuadables.



üåü Reflexi√≥n
Este proyecto fue una excelente oportunidad para explorar el modelado de uplift y trabajar con datasets grandes en un entorno distribuido como Microsoft Fabric. A pesar de los desaf√≠os con LightGBMClassifier, el uso de LogisticRegression permiti√≥ completar el an√°lisis, aunque con un uplift predicho modesto. En el futuro, me gustar√≠a abordar los problemas de compatibilidad con LightGBM o explorar otros meta-learners (como S-Learner o X-Learner) para mejorar las predicciones.
üë§ Autor: Juan Heriberto Rosas Ju√°rezüìß Correo: juanheriberto.rosas@jhrjdata.comüåê LinkedIn: Juan Heriberto Rosas Ju√°rezüè¢ Organizaci√≥n: Gobierno Digital e Innovaci√≥n
